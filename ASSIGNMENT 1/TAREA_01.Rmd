---
title: "ESTADISTICA APLICADA II: TAREA 1"
author: "Mauricio Vazquez Moran"
date: '2024-09-17'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(kableExtra)
```

<br>

## **EJERCICIO 01**

La Compañía Toluca fabrica equipos de refrigeración. En el pasado, las
refacciones de los equipos se han fabricado periódicamente en lotes de
diferentes tamaños. Se implementó un programa de mejora para lo cual los
directivos requieren conocer el tamaño óptimo de los lotes. Para determinar el
tamaño de los lotes se consideró la relación entre el tamaño de los lotes y la
cantidad de horas requeridas para producir el lote. Se levantaron datos de 25
corridas de producción recientes sobre el número de horas que se requirieron
(y) para producir lotes de diferentes tamaños (x). Suponiendo que el modelo
de regresión lineal simple es apropiado.

<br>

##### **Lectura de datos:**

```{r}
data <- read.table(file = "datos_ej_1.txt", header = FALSE, sep = "|", strip.white = TRUE, skip = 1)
names(data) <- c("Tamaños", "Num_horas")
head(data)

```

<br>

##### **A) Encuentra los estimadores de mínimos cuadrados para los coeficientes de la regresión.**

```{r}

x.barra <- mean(data$Tamaños)
y.barra <- mean(data$Num_horas)
data$dif.x <- data$Tamaños - x.barra
data$dif.y <- data$Num_horas - y.barra
data$dif.x_x_dif.y <- data$dif.x*data$dif.y
b.1.est <- sum(data$dif.x_x_dif.y)/sum((data$dif.x)^2)
b.0.est <- y.barra - b.1.est * x.barra

```

Obtuvimos que los estimadores de mínimos cuadrados para los coeficientes de la regresión son:

- $\beta_0 = `r b.0.est`$

- $\beta_1 = `r b.1.est`$

<br>

##### **B) Calcula el valor estimado de número de horas promedio que se requerirán cuando el lote es de tamaño 65.**

```{r}

y_hat <- b.0.est + b.1.est*65

```

Obtuvimos que el valor estimado de número de horas promedio que se requerirán cuando el lote es de tamaño 65 es:

- $\hat{y} = `r y_hat`$


<br>

##### **C) Estima el intervalo para \(\beta_1\) al 95% de confianza. ¿Qué se puede interpretar de este intervalo?**

```{r}

y.gorro <- b.0.est + b.1.est*data$Tamaños

se.b1.est <- 
  sqrt(sum(((data$Num_horas - y.gorro)^2)/(nrow(data)-2))) / 
  sqrt((sum((data$Tamaños - mean(data$Tamaños))^2)))

v.c <- qt(p = 0.975, df = nrow(data)-2)
i.c.1 <- b.1.est - v.c*se.b1.est
i.c.2 <- b.1.est + v.c*se.b1.est

```

El intervalo de confianza para \(\beta_1\) al 95% de confianza es: 

- $IC = (`r i.c.1`, `r i.c.2`)$

Intepretacion: el IC es el rango de valores dentro del cual se espera que caiga \(\beta_1\) de la población con un 95% de confianza. En otras palabras, si se repitiera el muestreo y el cálculo del intervalo muchas veces, aproximadamente el 95% de esos intervalos de confianza incluirían el valor real de \(\beta_1\).

<br>

##### **D) ¿Podríamos afirmar que la relación lineal es significativa? Realiza una prueba de hipótesis (significancia del 5%) para \(\beta_1\) que te permita contestar esta pregunta.**


```{r}

t_statistic <- b.1.est / se.b1.est

p_value <- 2 * pt(-abs(t_statistic), df = nrow(data) - 2)

if(p_value < 0.05) {
  cat("Rechazamos la hipotesis nula. Hay suficiente evidencia para concluir que beta_1 es diferente de 0, indicando una relación lineal significativa.\n")
} else {
  cat("No se rechaza la hipotesis nula. No hay suficiente evidencia para concluir que beta_1 es diferente de 0.\n")
}

```

<br>

##### **E) Supongamos ahora que se desea probar si la tasa de cambio en el número de horas por lote trabajado es positiva, ¿cómo establecerías la prueba de hipótesis? ¿Qué resultado te arroja?**

```{r}

t_statistic <- b.1.est / se.b1.est

p_value <- pt(t_statistic, df = nrow(data) - 2, lower.tail = FALSE) # para obtener el valor p de una cola hacia la derecha.

if(p_value < 0.05) {
  cat("Rechazamos la hipótesis nula. Hay suficiente evidencia para concluir que beta_1 es mayor que 0, indicando una tasa de cambio positiva en el número de horas por lote trabajado.\n")
} else {
  cat("No se rechaza la hipótesis nula. No hay suficiente evidencia para concluir que beta_1 es mayor que 0.\n")
}

```

<br>

##### **F) Construye un intervalo de confianza al 90% para \(\beta_0\).**

```{r}

MSE <- sum((data$Num_horas - y.gorro)^2)/(nrow(data)-2)

se.b0.est <- 
  sqrt(
    MSE * 
      (
        1 / nrow(data) + 
          x.barra^2 / ((sum((data$Tamaños - mean(data$Tamaños))^2)))
        )
    )

v.c <- qt(p = 0.95, df = nrow(data)-2)

i.c.1 <- b.0.est - v.c*se.b0.est
i.c.2 <- b.0.est + v.c*se.b0.est
t.est <- b.0.est / se.b0.est

```

El intervalo de confianza para \(\beta_0\) al 90% de confianza es: 

- $IC = (`r i.c.1`, `r i.c.2`)$

<br>

##### **G) Construye un intervalo de confianza al 90% para \(\hat{Y}_h\) si \(X_h = 65\) y \(X_h = 100\).**


```{r}

X_h1 <- 65
X_h2 <- 100
Y_h1 <- b.0.est + b.1.est * X_h1
Y_h2 <- b.0.est + b.1.est * X_h2

n <- nrow(data)
SSE <- sum((data$Num_horas - (b.0.est + b.1.est * data$Tamaños))^2)
MSE <- SSE / (n - 2)
S_xx <- sum((data$Tamaños - x.barra)^2)
SE_Y_h1 <- sqrt(MSE * (1/n + (X_h1 - x.barra)^2 / S_xx))
SE_Y_h2 <- sqrt(MSE * (1/n + (X_h2 - x.barra)^2 / S_xx))
alpha <- 0.10
t_critical <- qt(1 - alpha/2, df = n - 2)

IC_Y_h1_lower <- Y_h1 - t_critical * SE_Y_h1
IC_Y_h1_upper <- Y_h1 + t_critical * SE_Y_h1

IC_Y_h2_lower <- Y_h2 - t_critical * SE_Y_h2
IC_Y_h2_upper <- Y_h2 + t_critical * SE_Y_h2

```

El intervalo de confianza para \(Y_h\) al 90% de confianza si \(X_h=65\) es: 

- $IC = (`r IC_Y_h1_lower`, `r IC_Y_h1_upper`)$

El intervalo de confianza para \(Y_h\) al 90% de confianza si \(X_h=100\) es: 

- $IC = (`r IC_Y_h2_lower`, `r IC_Y_h2_upper`)$


<br>

##### **H) Supón que la empresa desea pronosticar el valor del número de horas que tomará producir un nuevo lote de 65 refacciones. Calcula el intervalo de confianza al 90% para el número de horas que tomará elaborar este lote. ¿Cuál es el intervalo de confianza para un nuevo lote de 100 piezas?.**

```{r}

X_h1 <- 65
X_h2 <- 100
Y_h1 <- b.0.est + b.1.est * X_h1
Y_h2 <- b.0.est + b.1.est * X_h2

n <- nrow(data)
SSE <- sum((data$Num_horas - (b.0.est + b.1.est * data$Tamaños))^2)
MSE <- SSE / (n - 2)
S_xx <- sum((data$Tamaños - x.barra)^2)
SE_Y_h1_pred <- sqrt(MSE * (1 + 1/n + (X_h1 - x.barra)^2 / S_xx))
SE_Y_h2_pred <- sqrt(MSE * (1 + 1/n + (X_h2 - x.barra)^2 / S_xx))

alpha <- 0.10
t_critical <- qt(1 - alpha/2, df = n - 2)

IP_Y_h1_lower <- Y_h1 - t_critical * SE_Y_h1_pred
IP_Y_h1_upper <- Y_h1 + t_critical * SE_Y_h1_pred

IP_Y_h2_lower <- Y_h2 - t_critical * SE_Y_h2_pred
IP_Y_h2_upper <- Y_h2 + t_critical * SE_Y_h2_pred

```

El intervalo de confianza (predicción) al 90% para un nuevo lote de 65 piezas es: 

- $IC = (`r IP_Y_h1_lower`, `r IP_Y_h1_upper`)$

El intervalo de confianza (predicción) al 90% para un nuevo lote de 100 piezas: es: 

- $IC = (`r IP_Y_h2_lower`, `r IP_Y_h2_upper`)$

<br>

##### **I) Realiza una prueba \( F \) para determinar si \(\beta = 0\) con un 95% de confianza.**

```{r}

modelo <- lm(Num_horas ~ Tamaños, data = data)
summary_modelo <- summary(modelo)

F_statistic <- summary_modelo$fstatistic[1]
p_value <- summary_modelo$coefficients["Tamaños", "Pr(>|t|)"]

if(p_value < 0.05) {
  cat("Rechazamos la hipótesis nula. Hay suficiente evidencia para concluir que beta es diferente de 0. \n")
} else {
  cat("No se rechaza la hipótesis nula. No hay suficiente evidencia para concluir que beta es diferente de 0. \n")
}

```

Como resultado de haber utilizado la funcion linear model (lm) en R, tenemos que:

- $Prueba F = `r F_statistic`$

- $Valor-p = `r p_value`$

<br>

##### **J) Obtén la \( R^2 \) de la regresión y proporciona una interpretación breve de este valor.**

```{r}

R2 <- summary_modelo$r.squared

```

Como resultado de haber utilizado la funcion linear model (lm) en R, tenemos que:

- $R^2 = `r R2`$

Representa la proporción de la variabilidad en la variable dependiente (Número de horas) que es explicada por la variable independiente (Tamaños) en el modelo. En nuestro caso nos dice que el 82.15% de la variabilidad en la variable dependiente (Número de horas) es explicada por la variable independiente (Tamaños) en el modelo de regresión.

<br>


## **EJERCICIO 02**

Una empresa que se dedica a la venta y mantenimiento de equipo de oficina
proporciona los datos que se proporcionan, relativos a 45 llamadas de
mantenimiento por parte de sus clientes. Los datos incluyen el número de
equipos (variable explicativa) a los que se les dio mantenimiento en cada
servicio y el tiempo (en minutos) que se tardó el personal de mantenimiento en
el servicio (variable dependiente). Suponiendo que el modelo de regresión
lineal simple de primer orden es válido:

<br>

##### **Lectura de datos:**

```{r}
data_02 <- read.table(file = "datos_ej_2.txt", header = FALSE, sep = "|", strip.white = TRUE)
names(data_02) <- c("Servicio", "Equipos")
head(data_02)

```

<br>

##### **A) Estima la función de regresión.**

```{r}

modelo <- lm(formula = Servicio ~ Equipos, data = data_02)
summary(modelo)

```

<br>

##### **B) Grafica tanto la función de regresión como los datos.**

```{r}

ggplot(data_02, aes(x = Equipos, y = Servicio)) +
  geom_point() +  
  geom_smooth(method = "lm", se = FALSE, color = "blue") +
  labs(title = "Relación entre Servicio y Equipos", x = "Equipos", y = "Tiempo de Servicio (minutos)") +
  theme_minimal()

```

<br>

##### **C) Proporciona una interpretación de los parámetros de regresión.**

Obtuvimos que los estimadores de los coeficientes de regresión son:

- $\hat{\beta}_0 = `r modelo$coefficients[1]`$

El término constante representaría el valor estimado del tiempo de servicio cuando el número de equipos es cero. Sin embargo, dado que el valor de $\beta_0$ es menor a cero, en este caso no tiene una interpretación práctica.

Por otro lado, obtuvimos que $\beta_1$ es:
 
- $\hat{\beta}_1 = `r modelo$coefficients[2]`$

Esto indica que por cada unidad adicional, el numero de equipos a los que se les dio mantenimiento, el tiempo de servicio aumenta en 15.04 minutos.

Añadiendo al analisis previo, por medio de los otros valores brindados por la regresión podemos concluir que:

- Dado que el valor $p < 2.2e^{-16}$, la relación encontrada entre el número de equipos y el tiempo de servicio es significativa.

- La prueba $F$, nos indica que el modelo en su conjunto es significativo.

- La $R^{2}$ nos indica que se logra explicar, en cierta medida, la variabilidad en el tiempo de servicio por la variabilidad en el numero de equipos.

<br>

##### **D) ¿Cuál es la estimación del tiempo que se tardará un mecánico en dar servicio a 5 equipos?**

- $Aproximadamente: 74.5958 min$

<br>

##### **E) Obtén los residuales y la suma del cuadrado de los residuales, ¿cuál es la relación entre esta suma del cuadrado de los residuales y la cantidad $Q=\sum_{i=1}^{n} (Y_i - \beta_0 - \beta_1 X_i)^2$ ?**

```{r}

residuales <- residuals(modelo)
SSE <- sum(residuales^2)

residuales_str <- toString(residuales)
SSE_str <- toString(SSE)

```

- Residuales: `` `r residuales_str` ``
- SSE:`` `r SSE_str` ``

Q es la suma de los errores exactos al cuadrado, mientras que la suma del cuadrado de los residuales es la suma del estimador epsilon al cuadrado.
- Errores exactos vs. estimacion

<br>

##### **F) Obtén los estimadores puntuales para $\sigma^2$ y $\sigma$. ¿En qué unidades se encuentra expresado $\sigma$?**

```{r}

n <- length(residuales)

sigmac_gorro <- sum(residuales^2) / (n - 2)
sigma_gorro <- sqrt(sigmac_gorro)


```

- $\hat{\sigma}^2 = \frac{SSR}{n - 2}$ : con un valor de $`r sigmac_gorro`$ y sus unidades son minutos al cuadrado.

- $\hat{\sigma} = \sqrt{\hat{\sigma}^2}$ : con un valor de $`r sigma_gorro`$ y sus unidades son minutos.

<br>

##### **G) Estima el cambio en el tiempo medio de servicio cuando el número de copiadoras incrementa en 1. Usa un intervalo de confianza al 90%. Interpreta tu intervalo de confianza.**

```{r}

residuales <- residuals(modelo)
SSE <- sum(residuales^2)

x.datos <- data_02$Equipos
x.barra <- mean(data_02$Equipos)
abajo <- sum((x.datos - x.barra)^2)

beta.1.gorro <- sum((data_02$Equipos - x.barra)*data_02$Servicio) / abajo
alpha <- 1 - 0.90
p <- 1-(alpha/2)

vc <- qt(p = p, df = n - 2)
y.gorro.dt <- predict(object = modelo)

mse <- SSE/n

sigma.2.gorro.b1 <- mse / abajo

ls <- beta.1.gorro + vc*sqrt(mse/abajo)
li <- beta.1.gorro - vc*sqrt(mse/abajo)

```
- Límite inferior: $`r li`$
- Límite inferior: $`r ls`$
- Intervalo = ($`r li`$, $`r ls`$)

<br>

##### **H) Realiza una prueba t con $\alpha = 0.1$ para determinar si existe una relación lineal entre \( X \) y \( Y \). Señala las hipótesis, la regla de decisión y tu conclusión. ¿Cuál es el $valor-p$ de la prueba?**

```{r}

summary_modelo <- summary(modelo)
valor_p <- summary_modelo$coefficients["Equipos", "Pr(>|t|)"]


```
- El p-value es de: $`r valor_p`$
- La regla de decisión es que si el valor $p < 0.05$ entonces tenemos que nuestro análisis es significativo y rechazamos $H_0$ a favor de $H_1$. 
- Con $H_0$ : $\beta_1$ = 0 vs. $H_0$ : $\beta_1$ $\neq$ 0.

En conclusion, hay evidencia para rechazar la hipotesis nula y aceptamos que hay relación lineal entre equipos y servicio.

<br>

##### **I) Los resultados obtenidos en G) y H), ¿son consistentes?**

- Observamos que el intervalo de confianza para la estimación de $\beta_1$ no contiene el valor 0. Además, la prueba t muestra un alto nivel de significancia. Estos resultados son coherentes, lo que sugiere que hay una relación lineal entre $X$ y $Y$. Por lo tanto, podemos afirmar esto con un alto grado de probabilidad y confianza.

<br>

##### **J) El fabricante sugiere que el tiempo medio requerido no debería incrementarse en más de 14 minutos por cada copiadora adicional. Realiza una prueba adicional para determinar si este estándar está siendo cumplido por la empresa. Controla para una $\alpha = 0.05$, señala las hipótesis, la regla de decisión y tu conclusión. ¿Cuál es el $valor-p$ de la prueba? **

```{r}

coeficiente_estimado <- coef(modelo)["Equipos"]
std_error <- summary(modelo)$coefficients["Equipos", "Std. Error"]
t_value <- (coeficiente_estimado - 14) / std_error

```

- El $valor-p$ es: $`r t_value`$

<br>

##### **K) ¿$\hat{\beta_0}$ proporciona alguna información relevante sobre el tiempo de “inicio” de una llamada de servicio?**

- En este caso, no tiene lógica tener una llamada de servicio si no hay equipos que requieran mantenimiento. Como se indicó anteriormente, esto no tiene una interpretación práctica.

<br>

##### **L) Calcula el intervalo al 90% de confianza para el tiempo medio de servicio en solicitudes en las que se pide dar servicio a seis equipos. Interpreta tu intervalo de confianza.** 

```{r}

tiempo_estimado_6 <- coef(modelo)["(Intercept)"] + coef(modelo)["Equipos"] * 6

n <- nrow(data_02)
x_bar <- mean(data_02$Equipos)
sigma_gorro <- sqrt(sum(residuals(modelo)^2) / (n - 2))
SE <- sigma_gorro * sqrt(1/n + (6 - x_bar)^2 / sum((data_02$Equipos - x_bar)^2))

t_test <- qt(0.95, df = n - 2)

margen_error <- t_test * SE
IC_inferior <- tiempo_estimado_6 - margen_error
IC_superior <- tiempo_estimado_6 + margen_error

```

- El intervalo de confianza es: ($`r IC_inferior`$,$`r IC_superior`$)

<br>

##### **M) Calcula el intervalo de confianza para la próxima solicitud de servicio que involucre seis equipos. Compara este intervalo con el del inciso anterior, ¿cuál debería ser mayor y por qué?**

```{r}

tiempo_estimado_6 <- coef(modelo)["(Intercept)"] + coef(modelo)["Equipos"] * 6

SE_prediccion <- sigma_gorro * sqrt(1 + 1/n + (6 - x_bar)^2 / sum((data_02$Equipos - x_bar)^2))
t_test <- qt(0.95, df = n - 2)

margen_error_prediccion <- t_test * SE_prediccion
IC_inferior_prediccion <- tiempo_estimado_6 - margen_error_prediccion
IC_superior_prediccion <- tiempo_estimado_6 + margen_error_prediccion

```

- El intervalo de confianza es: ($`r IC_inferior_prediccion`$,$`r IC_superior_prediccion`$)

- El segundo intervalo debería de tener un rango mayor ya que incluye el factor predicción.

<br>

##### **N) La administración desea estimar el tiempo esperado de servicio por equipo en solicitudes para seis equipos. Obtén el intervalo de confianza apropiado transformando el intervalo de confianza del inciso (l). Interpreta el intervalo de confianza calculado.**

- Dividiendo entre 6 el intervalo de confianza pasado, obtenemos $[14.55, 15.33]$. Este es el tiempo medio de servicio por equipo en minutos.

<br>

#####  **O) Determina los límites de la banda del 90% de confianza para la línea de regresión cuando \( X_h = 6 \). La banda en este punto, ¿es más ancha que los intervalos de confianza obtenidos en el inciso (l)? ¿Debería serlo?**

```{r}

y_gorro <- predict(modelo, newdata = data.frame(Equipos = 6), interval = "confidence", level = 0.90)[, "fit"]

n <- nrow(data_02)
x_bar <- mean(data_02$Equipos)
S_xx <- sum((data_02$Equipos - x_bar)^2)
sigma_hat <- sqrt(sum(residuals(modelo)^2) / (n - 2))

SE_y_gorro <- sigma_hat * sqrt(1 + 1/n + (6 - x_bar)^2 / S_xx)

t_critico <- qt(0.95, df = n - 2)

margen_error_banda <- t_critico * SE_y_gorro
banda_inf <- y_gorro - margen_error_banda
banda_sup <- y_gorro + margen_error_banda

```
- La banda de confianza es: ($`r banda_inf`$,$`r banda_sup`$)

- Definitivamente es mas ancha. Es lo que esperábamos dado que se tiene en cuenta la incertidumbre adicional en la predicción.

<br>

#####  **P) Obtén la tabla ANOVA para el modelo ajustado.**

```{r}

tabla_anova <- anova(modelo)
print(tabla_anova)

```

<br>

##### **Q) Realiza una prueba F para determinar si existe o no una relación lineal entre el tiempo empleado y el número de máquinas a las que se realizó el servicio. Usa un $\alpha = 0.10$.  Señala las hipótesis, la regla de decisión y tu conclusión.**

```{r}

resumen_modelo <- summary(modelo)
valor_p_f <- resumen_modelo$fstatistic[3]

print(valor_p_f)
if (valor_p_f < 0.05) {
  print("Rechazamos la hipótesis nula: hay una relación lineal significativa.")
} else {
  print("No rechazamos la hipótesis nula: no hay suficiente evidencia de una relación lineal significativa.")
}


```

<br>

##### **R) ¿En cuánto se reduce, en términos relativos, la variación total al incluir el número de máquinas como variable explicativa al análisis?**

```{r}
resumen_modelo <- summary(modelo)
r_cuadrado <- resumen_modelo$r.squared
reduccion_relativa <- r_cuadrado * 100
```
- La reducción relativa en la variación total es del $`r reduccion_relativa`$

- Recordar que:

\[ R^2 = \frac{\text{Variación explicada por el modelo}}{\text{Variación total}} = 1 - \frac{\text{SSE}}{\text{SST}} \]

donde:

- **SSE** es la suma de cuadrados del error (variación no explicada por el modelo).
- **SST** es la suma total de cuadrados (variación total de los datos).

<br>

##### **S) Calcula $r$, ¿cuál debería ser el signo de $r$?**

```{r}

r <- sqrt(summary(modelo)$r.squared)
signo_r <- ifelse(coef(modelo)["Equipos"] >= 0, "positivo", "negativo")

```

Esperaríamos que tuviera un signo positivo, ya que anticipamos una relación directa entre el servicio y el número de equipos.

- Un mayor número de equipos implica un mayor tiempo de servicio.

- El coeficiente de correlación r es $`r r`$ con signo $`r signo_r`$.

<br>

##### **T) Gráfica los residuales de la regresión contra \( \hat{Y} \) y contra \( X \).**

```{r}

data_02$residuales <- residuals(modelo)
data_02$valores_predichos <- fitted(modelo)

ggplot(data_02, aes(x = valores_predichos, y = residuales)) +
  geom_point() +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(title = "Residuales vs. Valores Predichos",
       x = "Valores Predichos (Servicio^)",
       y = "Residuales")

ggplot(data_02, aes(x = Equipos, y = residuales)) +
  geom_point() +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(title = "Residuales vs. Equipos",
       x = "Variable Independiente (Equipos)",
       y = "Residuales")

```
