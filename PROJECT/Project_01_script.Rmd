---
title: 'Proyecto Estadistica Aplicada II: Otoño 2024'
author: "Mauricio Vazquez Moran"
date: '2024-10-31'
output:
  pdf_document: default
  html_document: default
---

***Link del repositorio de GitHub: https://github.com/MauricioVazquezM/LINEAR_METHODS_ASSIGNMENTS_FALL2024***

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, tidy = TRUE, fig.width=10)

# Libraries
library(MASS)  
library(ggplot2)
library(GGally)
library(mclust)
library(kableExtra)
library(FactoMineR)
library(knitr)
library(caret)
library(dplyr)
library(gridExtra)
```

```{r, echo=FALSE}
# Lectura de los datos
data <- read.csv("C:/Users/mauva/OneDrive/Documents/ITAM/9no Semestre/METODOS LINEALES/REPOSITORIO/LINEAR_METHODS_ASSIGNMENTS_FALL2024/PROJECT/Student_Performance.csv")

# Nombres originales de las columnas
colnames(data) <- c("Hours.Studied", "Previous.Scores", "Extracurricular.Activities", 
                    "Sleep.Hours", "Sample.Question.Papers.Practiced", "Performance.Index")

# Renombrar las columnas (estandarizando los nombres de las columnas)
colnames(data) <- tolower(colnames(data))  
colnames(data) <- gsub("\\.", "_", colnames(data))  

# Acortar los nombres de las columnas
colnames(data) <- c("hrs_studied", "prev_scores", "xtr_activities", 
                    "sleep_hrs", "sample_questions", "performance_idx")
```

<br>

## Objetivo

* El conjunto de datos seleccionado para este proyecto tiene como objetivo explorar el impacto de las horas de estudio, los puntajes anteriores, las actividades extracurriculares, las horas de sueño y los exámenes de prueba en el rendimiento de los estudiantes. Se planea ajustar un modelo lineal simple para analizar el impacto de una de estas variables en la variable objetivo. Con el fin de determinar cuál de ellas explica mejor el rendimiento del estudiante por sí sola y brinda mejores resultados en términos de ajuste y predicción, se procedio a hacer un analisis exploratorio de los datos.

<br>

## Primeras observaciones

<br>

```{r, echo=FALSE}
# Revisando head
head(data) %>%
  kable(caption = "Muestra de los datos", booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped", "hold_position"))
```

***Descripción*** 

* El conjunto de datos de rendimiento estudiantil está diseñado para examinar los factores que influyen en el rendimiento académico de los estudiantes. Este consta de 10,000 registros de estudiantes, y cada registro contiene información sobre varios predictores y un índice de rendimiento.

***Variables***

* ***hrs_studied:*** número total de horas que cada estudiante dedicó al estudio.
* ***prev_scores:*** puntajes obtenidos por los estudiantes en pruebas anteriores.
* ***xtr_activities:*** Si el estudiante participa en actividades extracurriculares (sí o no).
* ***sleep_hrs:*** número promedio de horas de sueño que el estudiante tiene por día.
* ***sample_question:*** número de exámenes de prueba que el estudiante practicó.

***Variable objetivo***

* ***performance_idx:*** medida del rendimiento general de cada estudiante. El índice de rendimiento representa el desempeño académico del estudiante y ha sido redondeado al número entero más cercano. El índice varía entre 10 y 100, donde valores más altos indican un mejor rendimiento.


<br>

## Análisis exploratorio de datos

***Análisis univariado de los datos***

<br>

```{r echo=FALSE}
univar_analisis <- function(data) {
  results <- list()
  
  for (feature in colnames(data)) {
    data_type <- class(data[[feature]])[1]
    
    total <- nrow(data)
    nan_count <- sum(is.na(data[[feature]]))
    no_missings <- total - nan_count
    pct_missings <- nan_count / total
    
    if (is.numeric(data[[feature]])) {
      promedio <- round(mean(data[[feature]], na.rm = TRUE),2)
      desv_estandar <- round(sd(data[[feature]], na.rm = TRUE),2)
      varianza <- round(var(data[[feature]], na.rm = TRUE),2)
      minimo <- min(data[[feature]], na.rm = TRUE)
      p10 <- quantile(data[[feature]], 0.10, na.rm = TRUE)
      q1 <- quantile(data[[feature]], 0.25, na.rm = TRUE)
      mediana <- quantile(data[[feature]], 0.50, na.rm = TRUE)
      q3 <- quantile(data[[feature]], 0.75, na.rm = TRUE)
      p90 <- quantile(data[[feature]], 0.90, na.rm = TRUE)
      p95 <- quantile(data[[feature]], 0.95, na.rm = TRUE)
      p99 <- quantile(data[[feature]], 0.99, na.rm = TRUE)
      maximo <- max(data[[feature]], na.rm = TRUE)
      
      inf_count <- sum(is.infinite(data[[feature]]) & data[[feature]] > 0)
      neg_inf_count <- sum(is.infinite(data[[feature]]) & data[[feature]] < 0)
    } else {
      promedio <- NA
      desv_estandar <- NA
      varianza <- NA
      minimo <- NA
      p1 <- NA
      p5 <- NA
      p10 <- NA
      q1 <- NA
      mediana <- NA
      q3 <- NA
      p90 <- NA
      p95 <- NA
      p99 <- NA
      maximo <- NA
      inf_count <- 0
      neg_inf_count <- 0
    }
    
    results[[length(results) + 1]] <- list(
      
      Variable = feature,
      Total = total,
      No_Missings = no_missings,
      Missings = nan_count,
      Pct_Missings = pct_missings,
      Promedio = promedio,
      Desv_Std = desv_estandar,
      Varianza = varianza,
      Minimo = minimo,
      p10 = p10,
      q1 = q1,
      Mediana = mediana,
      q3 = q3,
      p90 = p90,
      p95 = p95,
      p99 = p99,
      Maximo = maximo
    )
  }
  
  result_df <- do.call(rbind, lapply(results, as.data.frame))
  
  rownames(result_df) <- NULL
  
  return(result_df)
  
}

# Ejecucion de lafuncion
resultados <- univar_analisis(data)

# Separando el analisis
resultados_parte1 <- resultados[, c("Variable", "Total", "No_Missings", "Missings", "Pct_Missings")]

resultados_parte2 <- resultados[, c("Promedio", "Desv_Std", "Varianza", "Minimo", "p10", "q1", "Mediana", "q3", "p90", "p95", "p99", "Maximo")]

# Ver los resultados en dos partes
resultados_parte1 %>%
  kable(caption = "Análisis univariado de los datos pt. I", booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped", "hold_position"))

resultados_parte2 %>%
  kable(caption = "Análisis univariado de los datos pt. II", booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped", "hold_position"))

```

* Observación 1: la mayoría de los estudiantes parece estudiar entre 3 y 7 horas, con algunos extremos que alcanzan hasta 9 horas.
* Observación 2: los puntajes anteriores muestran una amplia dispersión. La mitad de los estudiantes tiene puntajes superiores a 69, lo que sugiere que algunos estudiantes ya estaban bien preparados.
* Observación 3: la mayoría de los estudiantes duerme entre 5 y 9 horas, lo que indica una variabilidad notable en los hábitos de sueño.
* Observación 4: la mayoría de los estudiantes parece practicar de 2 a 7 exámenes, pero algunos practicaron significativamente más (hasta 9).
* Observación 5: existe una considerable variabilidad en el rendimiento estudiantil. Aunque la mediana es de 55, un grupo notable de estudiantes tiene un rendimiento significativamente más bajo o más alto.
* Observación 6: no hay valores faltantes en ninguna de las variables.

<br>

***Visualización de las variables***

Como objetivo de esta sección, se busca identificar patrones, detectar datos atípicos (outliers), analizar la estructura de los datos, examinar las relaciones entre las variables y comunicar, por medio de visualizaciones, para facilitar una mejor interpretación de los datos utilizados en este análisis.

\newpage

* **Explorando la variable 'performance_idx'**

```{r fig.align='center', fig.width=6, fig.height=3, echo=FALSE}
# Curva de la variable objetivo

# Crear el histograma 
histograma <- ggplot(data, aes(x = performance_idx)) +
  geom_histogram(binwidth = 10, fill = "green", color = "black", alpha = 0.7) +
  labs(title = "Histograma de performance index", x = "performance index", y = "Frecuencia") +
  theme_minimal()+
  theme(
    plot.title = element_text(size = 9),        
    axis.title = element_text(size = 8),         
    axis.text = element_text(size = 7)           
  )

# Crear la curva de densidad 
densidad <- ggplot(data, aes(x = performance_idx)) +
  geom_density(fill = "red", alpha = 0.5) +
  labs(title = "Curva de Densidad de performance index", x = "performance index", y = "Densidad") +
  theme_minimal()+
  theme(
    plot.title = element_text(size = 9),        
    axis.title = element_text(size = 8),         
    axis.text = element_text(size = 7)           
  )

# Mostrar ambos gráficos en un solo layout
grid.arrange(histograma, densidad, ncol = 2)
```

**Observaciones**

1. Los gráficos muestran una distribución simétrica, lo que sugiere que los datos podrían aproximarse a una distribución normal. Sin embargo, la forma no es la típica campana suave que caracteriza a una distribución normal estándar.
2. Existe una clara concentración de valores en el centro de la distribución. La mayoría de los valores del performance index se encuentran entre 40 y 80, según el histograma.
3. El gráfico de densidad revela una distribución multimodal, ya que se observan dos picos en la curva, lo que indica la presencia de más de un grupo de valores predominantes en los datos.

* **Explorando predictores de 'performance_idx'**

```{r fig.align='center',fig.width=7, fig.height=3.5, echo=FALSE}
# Muestreando
set.seed(123) 
data_sample <- data[sample(1:nrow(data), size = 300), ] 

# Crear cada scatterplot individualmente
scatter1 <- ggplot(data_sample, aes(x = hrs_studied, y = performance_idx)) +
  geom_point(color = 'blue') +
  labs(title = "Horas estudiadas vs Indice de performance", x = "hrs_studied", y = "performance_idx") +
  theme_minimal()+
  theme(
    plot.title = element_text(size = 9),        
    axis.title = element_text(size = 8),         
    axis.text = element_text(size = 7)           
  )

scatter2 <- ggplot(data_sample, aes(x = prev_scores, y = performance_idx)) +
  geom_point(color = 'green') +
  labs(title = "Scores anteriores vs Indice de performance", x = "prev_scores", y = "performance_idx") +
  theme_minimal()+
  theme(
    plot.title = element_text(size = 9),        
    axis.title = element_text(size = 8),         
    axis.text = element_text(size = 7)           
  )

scatter3 <- ggplot(data_sample, aes(x = sleep_hrs, y = performance_idx)) +
  geom_point(color = 'red') +
  labs(title = "Horas de sueño vs Indice de performance", x = "sleep_hrs", y = "performance_idx") +
  theme_minimal()+
  theme(
    plot.title = element_text(size = 9),        
    axis.title = element_text(size = 8),         
    axis.text = element_text(size = 7)           
  )

scatter4 <- ggplot(data_sample, aes(x = sample_questions, y = performance_idx)) +
  geom_point(color = 'purple') +
  labs(title = "Examenes practicados vs Indice de performance", x = "sample_questions", y = "performance_idx") +
  theme_minimal()+
  theme(
    plot.title = element_text(size = 9),        
    axis.title = element_text(size = 8),         
    axis.text = element_text(size = 7)           
  )

# Cuadrícula de 2x2
grid.arrange(scatter1, scatter2, scatter3, scatter4, ncol = 2)
```

**Observaciones**

1. No parece haber una relación clara entre las horas estudiadas y el índice de performance. Los puntos están dispersos a lo largo del eje 'performance_idx', lo que sugiere que estudiar más horas no necesariamente se traduce en un mejor performance.
2. A medida que aumentan los scores anteriores, el indice de performance también tiende a aumentar. Esto mencionado nos dice que una relación positiva entre el puntaje previo y el rendimiento actual. En otras palabras, indica que un buen desempeño en evaluaciones anteriores puede predecir un buen rendimiento en la evaluación actual.
3. Al igual que con las horas estudiadas, no hay un patrón claro entre las horas de sueño y el rendimiento. 
4. No se observa una relación clara entre el número de exámenes de práctica realizados y el índice de performance. Los puntos están distribuidos uniformemente en todas las categorías de 'sample questions'.

**Conclusión**

En el gráfico de dispersión entre la variable que representan los scores anteriores y el indice de performance, hay una clara relación positiva. A medida que los puntajes anteriores aumentan, también lo hace el índice de performance, lo que sugiere una relación lineal que podría modelarse efectivamente con una regresión lineal simple. 

Por otro lado, esta variable mencionada parece ser un fuerte predictor del índice de performance. La dispersión de los puntos sigue una tendencia ascendente notoria, indicativo que los valores altos de los scores anteriores se tienden a asociarse con valores altos del índice de performance. Por lo mencionado en los puntos antoriores, podemos hacer la suposición de que es un buen candidato para una predicción lineal.

```{r fig.align='center',fig.width=5, fig.height=3.5, echo=FALSE}

```

## Verificación de Supuestos

***Linealidad y Homocedasticidad***

* Recordar que la presencia de varianzas no constantes impacta fundamentalmente en la eficiencia de los estimadores y la estimación de la varianza de los estimadores.

```{r fig.align='center',fig.width=7, fig.height=2.5, echo=FALSE}
# Analisis de Linealidad y Homocedasticidad
modelo <- lm(data = data, formula = performance_idx ~ prev_scores)

data$residuals <- modelo$residuals
grupo.1 <- data[which(modelo$fitted.values <= median(modelo$fitted.values)),]
grupo.2 <- data[which(modelo$fitted.values > median(modelo$fitted.values)),]
mediana.epsilon.gorro.1 <- median(grupo.1$residuals)
mediana.epsilon.gorro.2 <- median(grupo.2$residuals)
grupo.1$d <- abs(grupo.1$residuals-mediana.epsilon.gorro.1)
grupo.2$d <- abs(grupo.2$residuals-mediana.epsilon.gorro.2)
d.media.1 <- mean(grupo.1$d)
d.media.2 <- mean(grupo.2$d)

SSD <- 
  (sum((grupo.1$d - d.media.1)^2) + sum((grupo.2$d - d.media.2)^2)) / 
  (nrow(data) - 2)

t.star.bf <- 
  abs(d.media.1 - d.media.2)/sqrt(SSD*(1/nrow(grupo.1) + 1/nrow(grupo.2)))

t.star.bf.p.value <- 
  pt(q = t.star.bf, df = nrow(data)-2, lower.tail = FALSE)

homo_1 <- ggplot(data = data) +
  aes(x = modelo$fitted.values, y = modelo$residuals) +
  geom_vline(xintercept = median(modelo$fitted.values)) +
  geom_hline(yintercept = 0) +
  geom_point() +
  theme_classic()

homo_2 <- ggplot(data = grupo.1) +
  aes(x = residuals) +
  geom_density() +
  geom_density(data = grupo.2, mapping = aes(x = residuals), colour = 'red') +
  theme_classic()

# Cuadrícula de 2x2
grid.arrange(homo_1, homo_2, ncol = 2)

```

* El plot nos indica que se cumplen razonablemente bien los supuestos de linealidad y homocedasticidad. Los residuos están distribuidos de manera aleatoria alrededor de cero, sin una tendencia visible, y la dispersión parece bastante constante a lo largo de los valores ajustados. Esto sugiere que el modelo de regresión lineal es adecuado y los supuestos básicos no parecen estar violados en este caso.
* El plot nos indica que  la curva roja (valores ajustados superiores a la mediana) tiene más picos en la parte superior, lo que sugiere una mayor variabilidad en los residuos en ese grupo en comparación con los valores ajustados por debajo de la mediana. Sin embargo, ambas curvas de densidad son bastante similares en general. La mayoría de los residuos están concentrados en torno a cero, lo que indica que tanto los valores ajustados por debajo como por encima de la mediana tienden a tener residuos centrados en torno a cero.

***Normalidad de los residuos***

```{r fig.align='center',fig.width=5, fig.height=2.5, echo=FALSE}
# COn un QQ plot
ggplot(data = data, aes(sample = residuals)) + 
  geom_qq() +
  geom_qq_line(color = "red") +  
  theme_classic() +
  labs(title = "Q-Q Plot de los Residuos", x = "Cuantiles Teóricos", y = "Cuantiles Muestrales")

```

* Como podemos observar, la mayoría de los puntos se alinean de manera bastante cercana a la línea diagonal, lo que indica que, en general, los residuos siguen una distribución aproximadamente normal en el centro de la distribución.

***Independencia de los Residuos***

```{r fig.align='center',fig.width=8, fig.height=3.5, echo=FALSE}
# Extrayendo los residuos del modelo para visualizacion
residuos <- modelo$residuals

# Crear una secuencia 
tiempo <- 1:length(residuos)

# Muestra seed
set.seed(123)  
sample_size <- 500  

# Muestreando los índices de los residuos y ordenarlos
indices_muestra <- sort(sample(tiempo, size = sample_size))

# Crear el gráfico con los datos muestreados
plot(tiempo[indices_muestra], residuos[indices_muestra], type = "l", 
     main = "Residuos a lo Largo del Tiempo (Muestreados y ordenados)", 
     xlab = "Índice de Observación", 
     ylab = "Residuos")
```

* Los residuos no tienen un patrón de cambio sistemático a lo largo del índice, lo cual es un indicativo de independencia de los residuos.

Con base en los resultados obtenidos, podemos concluir que se cumplen los supuestos de la regresión lineal. La distribución de los residuos y su comportamiento a lo largo del tiempo sugieren que no hay patrones evidentes de autocorrelación ni heterocedasticidad, y que la normalidad de los residuos es razonable. Por lo tanto, podemos asumir que el modelo de regresión lineal es adecuado para estos datos y que cumple con los supuestos necesarios para realizar inferencias confiables a partir de él.

<br>

## Ajuste de un modelo lineal simple

* Para entender la relación entre el índice de desempeño y las calificaciones anteriores, ajustamos un modelo de regresión lineal simple. Este modelo nos ayudará a evaluar la fuerza y la dirección de la relación entre las dos variables, permitiéndonos inferir si aumentos en las calificaciones previas están asociados con un incremento en el índice de desempeño actual del estudiante.

```{r, echo=FALSE}
# Modelo oficial
modelo_of <- lm(data = data, formula = performance_idx ~ prev_scores)

summary(modelo_of)
```

### Analisis del modelo propuesto

* **Residuales**

La mediana cercana a cero sugiere que los residuos están distribuidos simétricamente alrededor de cero. Esto indica que el modelo no tiene un sesgo. Por otro lado, el rango de los residuos (aproximadamente de -17.77 a 19.43) indica que existe variabilidad en la precisión del modelo.

* **Coeficientes**

El coeficiente de prev_scores es significativo y positivo, lo que indica que prev_scores es un buen predictor de performance_idx. En otras palabras, el indice de rendimiento tiende a aumentar, en promedio, en 1.0138 unidades por cada punto adicional en prev_scores. Ademas, los errores estándar bajos para ambos coeficientes sugieren que las estimaciones son precisas.

* **Residual Standard Error**

El valor de 7.744, en residual standard error, indica que, en promedio, los valores predichos por el modelo difieren de los valores observados en aproximadamente 7.744 unidades. Dado el valor de este, podemos decir que el modelo ajusta los datos bastante bien, con un error promedio relativamente pequeño en las predicciones del indice de performance.

* **R-squared**

El R-cuadrado de 0.8376 nos dice que el modelo tiene un buen ajuste y explica la mayoría de la variabilidad en performance_idx a partir de prev_scores. Esto nos indica que el modelo es robusto y adecuado

* **F-statistic**

El valor del estadistico F muy alto junto con un valor p extremadamente bajo nos indica que el modelo de regresión es altamente significativo. En otras palabras, sugiere que el predictor prev_scores tiene un impacto real en performance_idx y que el modelo es bueno para realizar predicciones.

<br>

```{r fig.align='center',fig.width=6, fig.height=4, echo=FALSE}
# Muestreando para visualizar
set.seed(42)  
sample_size <- 250  

# Muestreando los índices
indices_muestra <- sort(sample(tiempo, size = sample_size))
data_sample <- data[indices_muestra, ]

# Grafico de regresion
ggplot(data = data_sample) + 
  aes(x = prev_scores, y = performance_idx) +
  geom_point() +
  geom_smooth(method = 'lm', formula = y ~ x, se = TRUE) +
  theme_bw()
```

<br>

## ANOVA

```{r fig.width=10, fig.height=4.5, echo=FALSE}
anova(object = modelo_of)
```

1. Como se menciona arriba, mediante la estadística F alta y el valor p cercano a cero se confirma, en la tabla ANOVA, que el predictor prev_scores es estadísticamente significativo y tiene un efecto sobre indice de performance.
2. La suma de cuadrados explicada por prev_scores en comparación con la suma de cuadrados residual nos indica que prev_scores explica la mayor parte de la variabilidad en indice de performance.

<br>

## Conclusiones

* Con un alto R-cuadrado y un buen ajuste, el modelo es bueno para predecir el rendimiento escolar en función de los puntajes previos. Esto indica que el historial de rendimiento tiene un impacto significativo en el rendimiento futuro. 
* Por otro lado, aunque el modelo ajusta bien los datos, el rango de los residuos sugiere que existen algunas observaciones con mayores errores de predicción. Se considera que, para futuras iteraciones del proyecto, se debe examinar estos puntos. Lo cual puede resultar en comprender si hay factores adicionales que afectan el indice de rendimiento academico.

