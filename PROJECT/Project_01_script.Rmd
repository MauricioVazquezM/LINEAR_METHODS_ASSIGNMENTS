---
title: 'Proyecto Estadistica Aplicada II: Otoño 2024'
author: "Mauricio Vazquez Moran"
date: '2024-10-31'
output:
  pdf_document: default
  html_document: default
---

***Link del repositorio de GitHub: https://github.com/MauricioVazquezM/LINEAR_METHODS_ASSIGNMENTS_FALL2024***

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, tidy = TRUE, fig.width=10)

# Libraries
library(MASS)  
library(ggplot2)
library(GGally)
library(mclust)
library(kableExtra)
library(FactoMineR)
library(knitr)
library(caret)
library(dplyr)
library(gridExtra)
library(corrplot)
library(ggcorrplot)
library(car)
library(lmtest)
```

```{r, echo=FALSE}
# Lectura de los datos
data <- read.csv("C:/Users/mauva/OneDrive/Documents/ITAM/9no Semestre/METODOS LINEALES/REPOSITORIO/LINEAR_METHODS_ASSIGNMENTS_FALL2024/PROJECT/Student_Performance.csv")

# Nombres originales de las columnas
colnames(data) <- c("Hours.Studied", "Previous.Scores", "Extracurricular.Activities", 
                    "Sleep.Hours", "Sample.Question.Papers.Practiced", "Performance.Index")

# Renombrar las columnas (estandarizando los nombres de las columnas)
colnames(data) <- tolower(colnames(data))  
colnames(data) <- gsub("\\.", "_", colnames(data))  

# Acortar los nombres de las columnas
colnames(data) <- c("hrs_studied", "prev_scores", "xtr_activities", 
                    "sleep_hrs", "sample_questions", "performance_idx")
```

<br>

## Objetivo

* El conjunto de datos seleccionado para este proyecto tiene como objetivo explorar el impacto de las horas de estudio, los puntajes anteriores, las actividades extracurriculares, las horas de sueño y los exámenes de prueba en el rendimiento de los estudiantes. Se planea ajustar un modelo lineal simple para analizar el impacto de una de estas variables en la variable objetivo. Con el fin de determinar cuál de ellas explica mejor el rendimiento del estudiante por sí sola y brinda mejores resultados en términos de ajuste y predicción, se procedio a hacer un analisis exploratorio de los datos.

<br>

## Primeras observaciones

<br>

```{r, echo=FALSE}
# Revisando head
head(data) %>%
  kable(caption = "Muestra de los datos", booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped", "hold_position"))
```

***Descripción*** 

* El conjunto de datos de rendimiento estudiantil está diseñado para examinar los factores que influyen en el rendimiento académico de los estudiantes. Este consta de 10,000 registros de estudiantes, y cada registro contiene información sobre varios predictores y un índice de rendimiento.

***Variables***

* ***hrs_studied:*** número total de horas que cada estudiante dedicó al estudio.
* ***prev_scores:*** puntajes obtenidos por los estudiantes en pruebas anteriores.
* ***xtr_activities:*** Si el estudiante participa en actividades extracurriculares (sí o no).
* ***sleep_hrs:*** número promedio de horas de sueño que el estudiante tiene por día.
* ***sample_question:*** número de exámenes de prueba que el estudiante practicó.

***Variable objetivo***

* ***performance_idx:*** medida del rendimiento general de cada estudiante. El índice de rendimiento representa el desempeño académico del estudiante y ha sido redondeado al número entero más cercano. El índice varía entre 10 y 100, donde valores más altos indican un mejor rendimiento.


<br>

## Análisis exploratorio de datos

***Análisis univariado de los datos***

<br>

```{r echo=FALSE}
univar_analisis <- function(data) {
  results <- list()
  
  for (feature in colnames(data)) {
    data_type <- class(data[[feature]])[1]
    
    total <- nrow(data)
    nan_count <- sum(is.na(data[[feature]]))
    no_missings <- total - nan_count
    pct_missings <- nan_count / total
    
    if (is.numeric(data[[feature]])) {
      promedio <- round(mean(data[[feature]], na.rm = TRUE),2)
      desv_estandar <- round(sd(data[[feature]], na.rm = TRUE),2)
      varianza <- round(var(data[[feature]], na.rm = TRUE),2)
      minimo <- min(data[[feature]], na.rm = TRUE)
      p10 <- quantile(data[[feature]], 0.10, na.rm = TRUE)
      q1 <- quantile(data[[feature]], 0.25, na.rm = TRUE)
      mediana <- quantile(data[[feature]], 0.50, na.rm = TRUE)
      q3 <- quantile(data[[feature]], 0.75, na.rm = TRUE)
      p90 <- quantile(data[[feature]], 0.90, na.rm = TRUE)
      p95 <- quantile(data[[feature]], 0.95, na.rm = TRUE)
      p99 <- quantile(data[[feature]], 0.99, na.rm = TRUE)
      maximo <- max(data[[feature]], na.rm = TRUE)
      
      inf_count <- sum(is.infinite(data[[feature]]) & data[[feature]] > 0)
      neg_inf_count <- sum(is.infinite(data[[feature]]) & data[[feature]] < 0)
    } else {
      promedio <- NA
      desv_estandar <- NA
      varianza <- NA
      minimo <- NA
      p1 <- NA
      p5 <- NA
      p10 <- NA
      q1 <- NA
      mediana <- NA
      q3 <- NA
      p90 <- NA
      p95 <- NA
      p99 <- NA
      maximo <- NA
      inf_count <- 0
      neg_inf_count <- 0
    }
    
    results[[length(results) + 1]] <- list(
      
      Variable = feature,
      Total = total,
      No_Missings = no_missings,
      Missings = nan_count,
      Pct_Missings = pct_missings,
      Promedio = promedio,
      Desv_Std = desv_estandar,
      Varianza = varianza,
      Minimo = minimo,
      p10 = p10,
      q1 = q1,
      Mediana = mediana,
      q3 = q3,
      p90 = p90,
      p95 = p95,
      p99 = p99,
      Maximo = maximo
    )
  }
  
  result_df <- do.call(rbind, lapply(results, as.data.frame))
  
  rownames(result_df) <- NULL
  
  return(result_df)
  
}

# Ejecucion de lafuncion
resultados <- univar_analisis(data)

# Separando el analisis
resultados_parte1 <- resultados[, c("Variable", "Total", "No_Missings", "Missings", "Pct_Missings")]

resultados_parte2 <- resultados[, c("Promedio", "Desv_Std", "Varianza", "Minimo", "p10", "q1", "Mediana", "q3", "p90", "p95", "p99", "Maximo")]

# Ver los resultados en dos partes
resultados_parte1 %>%
  kable(caption = "Análisis univariado de los datos pt. I", booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped", "hold_position"))

resultados_parte2 %>%
  kable(caption = "Análisis univariado de los datos pt. II", booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped", "hold_position"))

```

* Observación 1: la mayoría de los estudiantes parece estudiar entre 3 y 7 horas, con algunos extremos que alcanzan hasta 9 horas.
* Observación 2: los puntajes anteriores muestran una amplia dispersión. La mitad de los estudiantes tiene puntajes superiores a 69, lo que sugiere que algunos estudiantes ya estaban bien preparados.
* Observación 3: la mayoría de los estudiantes duerme entre 5 y 9 horas, lo que indica una variabilidad notable en los hábitos de sueño.
* Observación 4: la mayoría de los estudiantes parece practicar de 2 a 7 exámenes, pero algunos practicaron significativamente más (hasta 9).
* Observación 5: existe una considerable variabilidad en el rendimiento estudiantil. Aunque la mediana es de 55, un grupo notable de estudiantes tiene un rendimiento significativamente más bajo o más alto.
* Observación 6: no hay valores faltantes en ninguna de las variables.

<br>

***Visualización de las variables***

Como objetivo de esta sección, se busca identificar patrones, detectar datos atípicos (outliers), analizar la estructura de los datos, examinar las relaciones entre las variables y comunicar, por medio de visualizaciones, para facilitar una mejor interpretación de los datos utilizados en este análisis.

\newpage

* **Explorando la variable 'performance_idx'**

```{r fig.align='center', fig.width=6, fig.height=3, echo=FALSE}
# Curva de la variable objetivo

# Crear el histograma 
histograma <- ggplot(data, aes(x = performance_idx)) +
  geom_histogram(binwidth = 10, fill = "green", color = "black", alpha = 0.7) +
  labs(title = "Histograma de performance index", x = "performance index", y = "Frecuencia") +
  theme_minimal()+
  theme(
    plot.title = element_text(size = 9),        
    axis.title = element_text(size = 8),         
    axis.text = element_text(size = 7)           
  )

# Crear la curva de densidad 
densidad <- ggplot(data, aes(x = performance_idx)) +
  geom_density(fill = "red", alpha = 0.5) +
  labs(title = "Curva de Densidad de performance index", x = "performance index", y = "Densidad") +
  theme_minimal()+
  theme(
    plot.title = element_text(size = 9),        
    axis.title = element_text(size = 8),         
    axis.text = element_text(size = 7)           
  )

# Mostrar ambos gráficos en un solo layout
grid.arrange(histograma, densidad, ncol = 2)
```

**Observaciones**

1. Los gráficos muestran una distribución simétrica, lo que sugiere que los datos podrían aproximarse a una distribución normal. Sin embargo, la forma no es la típica campana suave que caracteriza a una distribución normal estándar.
2. Existe una clara concentración de valores en el centro de la distribución. La mayoría de los valores del performance index se encuentran entre 40 y 80, según el histograma.
3. El gráfico de densidad revela una distribución multimodal, ya que se observan dos picos en la curva, lo que indica la presencia de más de un grupo de valores predominantes en los datos.

* **Explorando predictores de 'performance_idx'**

```{r fig.align='center',fig.width=7, fig.height=3.5, echo=FALSE}
# Muestreando
set.seed(123) 
data_sample <- data[sample(1:nrow(data), size = 300), ] 

# Crear cada scatterplot individualmente
scatter1 <- ggplot(data_sample, aes(x = hrs_studied, y = performance_idx)) +
  geom_point(color = 'blue') +
  labs(title = "Horas estudiadas vs Indice de performance", x = "hrs_studied", y = "performance_idx") +
  theme_minimal()+
  theme(
    plot.title = element_text(size = 9),        
    axis.title = element_text(size = 8),         
    axis.text = element_text(size = 7)           
  )

scatter2 <- ggplot(data_sample, aes(x = prev_scores, y = performance_idx)) +
  geom_point(color = 'green') +
  labs(title = "Scores anteriores vs Indice de performance", x = "prev_scores", y = "performance_idx") +
  theme_minimal()+
  theme(
    plot.title = element_text(size = 9),        
    axis.title = element_text(size = 8),         
    axis.text = element_text(size = 7)           
  )

scatter3 <- ggplot(data_sample, aes(x = sleep_hrs, y = performance_idx)) +
  geom_point(color = 'red') +
  labs(title = "Horas de sueño vs Indice de performance", x = "sleep_hrs", y = "performance_idx") +
  theme_minimal()+
  theme(
    plot.title = element_text(size = 9),        
    axis.title = element_text(size = 8),         
    axis.text = element_text(size = 7)           
  )

scatter4 <- ggplot(data_sample, aes(x = sample_questions, y = performance_idx)) +
  geom_point(color = 'purple') +
  labs(title = "Examenes practicados vs Indice de performance", x = "sample_questions", y = "performance_idx") +
  theme_minimal()+
  theme(
    plot.title = element_text(size = 9),        
    axis.title = element_text(size = 8),         
    axis.text = element_text(size = 7)           
  )

# Cuadrícula de 2x2
grid.arrange(scatter1, scatter2, scatter3, scatter4, ncol = 2)
```

**Observaciones**

1. No parece haber una relación clara entre las horas estudiadas y el índice de performance. Los puntos están dispersos a lo largo del eje 'performance_idx', lo que sugiere que estudiar más horas no necesariamente se traduce en un mejor performance.
2. A medida que aumentan los scores anteriores, el indice de performance también tiende a aumentar. Esto mencionado nos dice que una relación positiva entre el puntaje previo y el rendimiento actual. En otras palabras, indica que un buen desempeño en evaluaciones anteriores puede predecir un buen rendimiento en la evaluación actual.
3. Al igual que con las horas estudiadas, no hay un patrón claro entre las horas de sueño y el rendimiento. 
4. No se observa una relación clara entre el número de exámenes de práctica realizados y el índice de performance. Los puntos están distribuidos uniformemente en todas las categorías de 'sample questions'.

**Conclusión EDA**

En el gráfico de dispersión entre la variable que representan los scores anteriores y el indice de performance, hay una clara relación positiva. A medida que los puntajes anteriores aumentan, también lo hace el índice de performance, lo que sugiere una relación lineal que podría modelarse efectivamente con una regresión lineal simple. 

Por otro lado, esta variable mencionada parece ser un fuerte predictor del índice de performance. La dispersión de los puntos sigue una tendencia ascendente notoria, indicativo que los valores altos de los scores anteriores se tienden a asociarse con valores altos del índice de performance. Por lo mencionado en los puntos antoriores, podemos hacer la suposición de que es un buen candidato para una predicción lineal.


## Ajuste de un modelo lineal simple

* Para entender la relación entre el índice de desempeño y las calificaciones anteriores, ajustamos un modelo de regresión lineal simple. Este modelo nos ayudará a evaluar la fuerza y la dirección de la relación entre las dos variables, permitiéndonos inferir si aumentos en las calificaciones previas están asociados con un incremento en el índice de desempeño actual del estudiante.

```{r, echo=FALSE}
# Modelo oficial
modelo_of <- lm(data = data, formula = performance_idx ~ prev_scores)

summary(modelo_of)
```

\newpage

### Analisis del modelo propuesto

* **Residuales**

La mediana cercana a cero sugiere que los residuos están distribuidos simétricamente alrededor de cero. Esto indica que el modelo no tiene un sesgo. Por otro lado, el rango de los residuos (aproximadamente de -17.77 a 19.43) indica que existe variabilidad en la precisión del modelo.

* **Coeficientes**

El coeficiente de prev_scores es significativo y positivo, lo que indica que prev_scores es un buen predictor de performance_idx. En otras palabras, el indice de rendimiento tiende a aumentar, en promedio, en 1.0138 unidades por cada punto adicional en prev_scores. Ademas, los errores estándar bajos para ambos coeficientes sugieren que las estimaciones son precisas.

* **Residual Standard Error**

El valor de 7.744, en residual standard error, indica que, en promedio, los valores predichos por el modelo difieren de los valores observados en aproximadamente 7.744 unidades. Dado el valor de este, podemos decir que el modelo ajusta los datos bastante bien, con un error promedio relativamente pequeño en las predicciones del indice de performance.

* **R-squared**

El R-cuadrado de 0.8376 nos dice que el modelo tiene un buen ajuste y explica la mayoría de la variabilidad en performance_idx a partir de prev_scores. Esto nos indica que el modelo es robusto y adecuado

* **F-statistic**

El valor del estadistico F muy alto junto con un valor p extremadamente bajo nos indica que el modelo de regresión es altamente significativo. En otras palabras, sugiere que el predictor prev_scores tiene un impacto real en performance_idx y que el modelo es bueno para realizar predicciones.

```{r fig.align='center',fig.width=5, fig.height=3, echo=FALSE}
# Muestreando para visualizar
set.seed(42)  
sample_size <- 250  

# Crear una secuencia 
residuos <- modelo_of$residuals
tiempo <- 1:length(residuos)

# Muestreando los índices
indices_muestra <- sort(sample(tiempo, size = sample_size))
data_sample <- data[indices_muestra, ]

# Grafico de regresion
ggplot(data = data_sample) + 
  aes(x = prev_scores, y = performance_idx) +
  geom_point() +
  geom_smooth(method = 'lm', formula = y ~ x, se = TRUE) +
  theme_bw()
```

### ANOVA

```{r fig.width=10, fig.height=4.5, echo=FALSE}
anova(object = modelo_of)
```

1. Como se menciona arriba, mediante la estadística F alta y el valor p cercano a cero se confirma, en la tabla ANOVA, que el predictor prev_scores es estadísticamente significativo y tiene un efecto sobre indice de performance.
2. La suma de cuadrados explicada por prev_scores en comparación con la suma de cuadrados residual nos indica que prev_scores explica la mayor parte de la variabilidad en indice de performance.

<br>

## Verificación de Supuestos

***Linealidad y Homocedasticidad***

* Recordar que la presencia de varianzas no constantes impacta fundamentalmente en la eficiencia de los estimadores y la estimación de la varianza de los estimadores.

```{r fig.align='center',fig.width=7, fig.height=2.5, echo=FALSE}
# Analisis de Linealidad y Homocedasticidad
modelo <- lm(data = data, formula = performance_idx ~ prev_scores)

data$residuals <- modelo$residuals
grupo.1 <- data[which(modelo$fitted.values <= median(modelo$fitted.values)),]
grupo.2 <- data[which(modelo$fitted.values > median(modelo$fitted.values)),]
mediana.epsilon.gorro.1 <- median(grupo.1$residuals)
mediana.epsilon.gorro.2 <- median(grupo.2$residuals)
grupo.1$d <- abs(grupo.1$residuals-mediana.epsilon.gorro.1)
grupo.2$d <- abs(grupo.2$residuals-mediana.epsilon.gorro.2)
d.media.1 <- mean(grupo.1$d)
d.media.2 <- mean(grupo.2$d)

SSD <- (sum((grupo.1$d - d.media.1)^2) + sum((grupo.2$d - d.media.2)^2)) / (nrow(data) - 2)

t.star.bf <- abs(d.media.1 - d.media.2)/sqrt(SSD*(1/nrow(grupo.1) + 1/nrow(grupo.2)))

t.star.bf.p.value <- pt(q = t.star.bf, df = nrow(data)-2, lower.tail = FALSE)

# Muestreo de 100 filas en df auxiliar
auxiliar <- data.frame(residuales = residuals(modelo),
                       valores_ajustados = fitted(modelo))
sample_lh <- auxiliar[sample(nrow(auxiliar), size = 100, replace = FALSE), ]

homo_1 <- ggplot(data = sample_lh, aes(x = valores_ajustados, y = residuales)) +
  geom_vline(xintercept = median(sample_lh$valores_ajustados)) +
  geom_hline(yintercept = 0) +
  geom_point() +
  labs(x = "valores ajustados", y = "residuales") +
  theme_classic()

homo_2 <- ggplot(data = grupo.1) +
  aes(x = residuals) +
  geom_density() +
  geom_density(data = grupo.2, mapping = aes(x = residuals), colour = 'red') +
  labs(x = "densidad", y = "residuales") +
  theme_classic()

# Cuadrícula de 2x2
grid.arrange(homo_1, homo_2, ncol = 2)

```

* El plot nos indica que se cumplen razonablemente bien los supuestos de linealidad y homocedasticidad. Los residuos están distribuidos de manera aleatoria alrededor de cero, sin una tendencia visible, y la dispersión parece bastante constante a lo largo de los valores ajustados. Esto sugiere que el modelo de regresión lineal es adecuado y los supuestos básicos no parecen estar violados en este caso.
* El plot nos indica que  la curva roja (valores ajustados superiores a la mediana) tiene más picos en la parte superior, lo que sugiere una mayor variabilidad en los residuos en ese grupo en comparación con los valores ajustados por debajo de la mediana. Sin embargo, ambas curvas de densidad son bastante similares en general. La mayoría de los residuos están concentrados en torno a cero, lo que indica que tanto los valores ajustados por debajo como por encima de la mediana tienden a tener residuos centrados en torno a cero.

\newpage

***Normalidad de los residuos***

```{r fig.align='center',fig.width=5, fig.height=2.5, echo=FALSE}
# COn un QQ plot
ggplot(data = data, aes(sample = residuals)) + 
  geom_qq() +
  geom_qq_line(color = "red") +  
  theme_classic() +
  labs(title = "Q-Q Plot de los Residuos", x = "Cuantiles Teóricos", y = "Cuantiles Muestrales")

```

* Como podemos observar, la mayoría de los puntos se alinean de manera bastante cercana a la línea diagonal, lo que indica que, en general, los residuos siguen una distribución aproximadamente normal en el centro de la distribución.

***Independencia de los Residuos***

```{r fig.align='center',fig.width=8, fig.height=3.5, echo=FALSE}
# Extrayendo los residuos del modelo para visualizacion
residuos <- modelo$residuals

# Crear una secuencia 
tiempo <- 1:length(residuos)

# Muestra seed
set.seed(123)  
sample_size <- 500  

# Muestreando los índices de los residuos y ordenarlos
indices_muestra <- sort(sample(tiempo, size = sample_size))

# Crear el gráfico con los datos muestreados
plot(tiempo[indices_muestra], residuos[indices_muestra], type = "l", 
     main = "Residuos a lo Largo del Tiempo (Muestreados y ordenados)", 
     xlab = "Índice de Observación", 
     ylab = "Residuos")
```

* Los residuos no tienen un patrón de cambio sistemático a lo largo del índice, lo cual es un indicativo de independencia de los residuos.

Con base en los resultados obtenidos, podemos concluir que se cumplen los supuestos de la regresión lineal. La distribución de los residuos y su comportamiento a lo largo del tiempo sugieren que no hay patrones evidentes de autocorrelación ni heterocedasticidad, y que la normalidad de los residuos es razonable. Por lo tanto, podemos asumir que el modelo de regresión lineal es adecuado para estos datos y que cumple con los supuestos necesarios para realizar inferencias confiables a partir de él.

### Conclusiones (Primera entrega)

* Con un alto R-cuadrado y un buen ajuste, el modelo es bueno para predecir el rendimiento escolar en función de los puntajes previos. Esto indica que el historial de rendimiento tiene un impacto significativo en el rendimiento futuro. 
* Por otro lado, aunque el modelo ajusta bien los datos, el rango de los residuos sugiere que existen algunas observaciones con mayores errores de predicción. Se considera que, para futuras iteraciones del proyecto, se debe examinar estos puntos. Lo cual puede resultar en comprender si hay factores adicionales que afectan el indice de rendimiento academico.


\newpage

## Ajuste de un modelo lineal múltiple

En esta segunda iteración del proyecto, se incorporarán las demás variables previamente analizadas para enriquecer el modelo inicial y mejorar su capacidad predictiva. Este enfoque permitirá explorar de manera más integral las relaciones entre las variables predictoras y la variable objetivo. Como resultado, se plantea transformar el modelo original en un modelo de regresión lineal múltiple, lo que permitirá capturar, de manera más precisa, las interacciones y contribuciones de cada factor al rendimiento estudiantil.

Una vez hecho este ejercicio, tenemos como resultado la siguiente ecuación:

```{r fig.width=10, fig.height=4.5, echo=FALSE}
# Modelo de regresión lineal múltiple
modelo_m <- lm(performance_idx ~ hrs_studied + prev_scores + xtr_activities + sleep_hrs + sample_questions, data = data)

# Extraer coeficientes del modelo
coeficientes <- coef(modelo_m)

# Construir la fórmula como texto
intercept <- round(coeficientes[1], 3)
coef_hrs_st <- round(coeficientes[2], 3)
coef_p_scr <- round(coeficientes[3], 3)
coef_xtr_act <- round(coeficientes[4], 3)
coef_s_hrs <- round(coeficientes[5], 3)
coef_s_ques <- round(coeficientes[6], 3)
```

\begin{align*}
\hat{Y}_{\text{performance\_idx}} = `r intercept` &+ `r coef_hrs_st` \cdot X_{\text{hrs\_studied}} + `r coef_p_scr` \cdot X_{\text{prev\_scores}}\\
&+ `r coef_xtr_act` \cdot X_{\text{xtr\_activities}} + `r coef_s_hrs` \cdot X_{\text{sleep\_hrs}} \\ 
&+ `r coef_s_ques` \cdot X_{\text{sample\_questions}} + \epsilon\\
\end{align*}

```{r fig.width=10, fig.height=4.5, echo=FALSE}
# Resumen del modelo
summary(modelo_m)
```

***Interpretación***

* $\beta_{0} = `r intercept`$: El valor predicho del índice de rendimiento cuando todas las variables predictoras son 0. En este caso, no puede ser interpretable en un contexto práctico. 
* $\beta_{hrs-studied} = `r coef_hrs_st`$: Por cada hora adicional de estudio, el índice de rendimiento aumenta en promedio 2.85 puntos, manteniendo constantes las demás variables.
* $\beta_{prev-scores} = `r coef_p_scr`$: Por cada punto adicional en los puntajes previos, el índice de rendimiento aumenta en promedio 1.01 puntos.
* $\beta_{xtr-activites} = `r coef_xtr_act`$: Participar en actividades extracurriculares (frente a no participar) está asociado con un aumento promedio de 0.61 puntos en el índice de rendimiento. Aunque el efecto es pequeño, es estadísticamente significativo.
* $\beta_{sleep-hours} = `r coef_s_hrs`$: Por cada hora adicional de sueño promedio por día, el índice de rendimiento aumenta en promedio 0.48 puntos, manteniendo constantes las demás variables.
* $\beta_{sample-questions} = `r coef_s_ques`$: Por cada examen de práctica adicional, el índice de rendimiento aumenta en promedio 0.19 puntos. Aunque el efecto es menor en comparación con otras variables, sigue siendo estadísticamente significativo.

Por otro lado, aunque se ya se menciono previamente arriba, todas las variables tienen valores de $p < 0.001$, lo que indica que sus coeficientes son estadísticamente significativos. Esto implica que todas las variables predictoras están asociadas con cambios significativos en el índice de rendimiento.

En cuanto a $R^2_{ajustado} =  0.9887$, se sugiere que las variables predictoras incluidas son útiles para explicar la variabilidad en los datos. Agregando que $F_{statistic} = 1.757e+05$ con un $p_{value} < 2e-16$ que nos indica que el modelo completo (con todas las variables predictoras) es significativamente mejor que un modelo sin predictores (modelo nulo).

### ANOVA

```{r fig.width=10, fig.height=4.5, echo=FALSE}
# Resumen del modelo
anova(modelo_m)
```

Como se puede analizar en la ANOVA realizado, el predictor $prev-scores$ es la variable más importante en términos de contribución a la explicación de la variabilidad en $performance-idx$, lo que sugiere que el desempeño previo es el mayor predictor del rendimiento actual. Esto se repalda por lo analizado en el exploratorio de datos. Por su parte, $hrs-studied$ también tiene un impacto significativo, demostrando que las horas de estudio son un factor clave en el rendimiento académico. Aunque las variables $xtr-activities$, $sleep-hrs$ y $sample-questions$ son estadísticamente significativas, su impacto relativo es menor en comparación con las dos variables principales. Finalmente, la cantidad de variabilidad no explicada por el modelo (residuos) es muy baja, lo que respalda el alto $R^2 = 0.9888$ del modelo.

### Diagnóstico del modelo 

El diagnóstico del modelo lineal múltiple es un paso fundamental para evaluar la validez y la calidad del ajuste del modelo. Este análisis se centrará en verificar los principales supuestos asociados con este tipo de modelos. En primer lugar, se diagnosticará el supuesto de linealidad, evaluando si la relación entre las variables predictoras y la variable dependiente es adecuada. A continuación, se analizarán los residuos para identificar patrones o problemas de especificación en el modelo. Asimismo, se evaluará la presencia de heterocedasticidad, que puede indicar varianzas no constantes en los residuos, y la normalidad de los mismos, requisito esencial para realizar inferencias válidas. Por último, se examinará la multicolinealidad entre las variables predictoras, asegurando que no existan relaciones fuertes entre ellas que puedan afectar la interpretación de los coeficientes del modelo. Este diagnóstico permitirá validar la robustez del modelo y garantizar que los resultados obtenidos sean fiables y adecuados.

### 1. Linealidad

Como lo visto en clase, el primer supuesto que analizaremos es el de la linealidad. En el contexto de la regresión, cuando hablamos de un modelo lineal, nos referimos principalmente a que sea lineal en los coeficientes de la regresión. En el análisis realizado hasta ahora, ya hemos explorado de alguna forma este supuesto. Sin embargo, es posible que nuestro modelo sea aproximadamente lineal, lo que podría permitir obtener coeficientes de regresión significativos y explicar una parte importante de la variabilidad de la variable respuesta, mientras que, al mismo tiempo, puede mostrar ciertos indicios de no linealidad.

```{r, fig.align='center', fig.width=6, fig.height=4, echo=FALSE}
# ("hrs_studied", "prev_scores", "xtr_activities", "sleep_hrs", "sample_questions", "performance_idx")

## Otras dimensiones
data$hrs_studied.sq <- data$hrs_studied**2
data$prev_scores.sq <- data$prev_scores**2
data$sleep_hrs.sq <- data$sleep_hrs**2
data$sample_questions.sq <- data$sample_questions**2

## Modelo dos
modelo_m2 <- lm(performance_idx ~ hrs_studied.sq + prev_scores.sq + sleep_hrs.sq + sample_questions.sq, data = data)

# Residuales y valores ajustados
residuales_m2 <- residuals(modelo_m2)
valores_ajustados2 <- fitted(modelo_m2)

# DF auxiliar
residuals_df2 <- data.frame(Residuales = residuales_m2,
                              ValoresAjustados = valores_ajustados2,
                              X_1 = data$hrs_studied.sq,
                              X_2 = data$prev_scores.sq,
                              X_3 = data$sample_questions.sq,
                              X_4 = data$sleep_hrs.sq
                            )

# Muestreo de 100 filas
muestreado2 <- residuals_df2[sample(nrow(residuals_df2), size = 100, replace = FALSE), ]

# Plot residuales vs X_1
plot2 <- ggplot(muestreado2, aes(x = Residuales, y = X_1)) +
  geom_point(alpha = 0.7) +
  labs(title = "vs. hrs_studied (squared)", x = "Residuales", y = "hrs_studied (squared)") +
  theme_minimal()

# Plot residuales vs X_2
plot3 <- ggplot(muestreado2, aes(x = Residuales, y = X_2)) +
  geom_point(alpha = 0.7) +
  labs(title = "vs. prev_scores (squared)", x = "Residuales", y = "prev_scores (squared)") +
  theme_minimal()

# Plot residuales vs X_3
plot4 <- ggplot(muestreado2, aes(x = Residuales, y = X_3)) +
  geom_point(alpha = 0.7) +
  labs(title = "vs. sample_questions (squared)", x = "Residuales", y = "sample_questions (squared)") +
  theme_minimal()

# Plot residuales vs X_4
plot5 <- ggplot(muestreado2, aes(x = Residuales, y = X_4)) +
  geom_point(alpha = 0.7) +
  labs(title = "vs. sleep_hrs (squared)", x = "Residuales", y = "sleep_hrs (squared)") +
  theme_minimal()

# Grid
grid.arrange(plot2, plot3, plot4, plot5, ncol = 2)
```

Observaciones:

* Los gráficos de residuos contra hrs_studied (squared), sample_questions (squared) y sleep_hrs (squared) no muestran patrones claros que sugieran no linealidad. Por lo tanto, los términos cuadráticos de estas variables podrían no ser necesarios en el modelo.
* Por otro lado, pareciera que hay evidencia de una relación no lineal entre prev_scores y la variable dependiente, particularmente en valores altos de prev_scores. Esto podría justificar mantener el término cuadrático en el modelo. Se determinara esto con los análisis posteriores.

```{r fig.width=10, fig.height=4.5, echo=FALSE}
# Rainbow test
raintest(modelo_m)
```

Dado el $p_{value}=0.0342$, se rechaza $H_0$ al nivel de siginifcancia de $\alpha = 0.05$. Lo cuá implica que hay indicios de no linealidad en la relación entre las variables predictoras y la variable dependiente. En otras palabras, el modelo lineal múltiple podría no ser la mejor opción para capturar completamente la relación entre las variables. Por lo tanto, se necesita una revisión analitica mas detallada.

### 2. Análisis de los residuales

```{r, fig.align='center', fig.width=9, fig.height=6, echo=FALSE}
# ("hrs_studied", "prev_scores", "xtr_activities", "sleep_hrs", "sample_questions", "performance_idx")
# Residuales y valores ajustados
residuales <- residuals(modelo_m)
valores_ajustados <- fitted(modelo_m)

# variable X_1 * X_2
data$X1_X2 <- data$sample_questions / data$hrs_studied

# DF auxiliar
residuals_df <- data.frame(
  Residuales = residuales,
  ValoresAjustados = valores_ajustados,
  X_1 = data$hrs_studied,
  X_2 = data$prev_scores,
  X_3 = data$xtr_activities,
  X_4 = data$sleep_hrs,
  X_5 = data$sample_questions,
  X1_X2 = data$X1_X2
)

# # Muestreo de 100 filas aleatorias sin reemplazo
set.seed(123)  
muestreado <- residuals_df[sample(nrow(data), size = 100, replace = FALSE), ]

# Plot residuales vs valores ajustados
plot1 <- ggplot(muestreado, aes(x = Residuales, y = ValoresAjustados)) +
  geom_point(alpha = 0.7) +
  labs(title = "vs. Valores Ajustados", x = "Residuales", y = "Y_hat") +
  theme_minimal()

# Plot residuales vs X_1
plot2 <- ggplot(muestreado, aes(x = Residuales, y = X_1)) +
  geom_point(alpha = 0.7) +
  labs(title = "vs. hrs_studied", x = "Residuales", y = "hrs_studied") +
  theme_minimal()

# Plot residuales vs X_2
plot3 <- ggplot(muestreado, aes(x = Residuales, y = X_2)) +
  geom_point(alpha = 0.7) +
  labs(title = "vs. prev_scores", x = "Residuales", y = "prev_scores") +
  theme_minimal()

# Plot residuales vs X_3
plot4 <- ggplot(muestreado, aes(x = Residuales, y = X_3)) +
  geom_point(alpha = 0.7) +
  labs(title = "vs. xtr_activities", x = "Residuales", y = "xtr_activities") +
  theme_minimal()

# Plot residuales vs X_4
plot5 <- ggplot(muestreado, aes(x = Residuales, y = X_4)) +
  geom_point(alpha = 0.7) +
  labs(title = "vs. sleep_hrs", x = "Residuales", y = "sleep_hrs") +
  theme_minimal()

# Plot residuales vs X_5
plot6 <- ggplot(muestreado, aes(x = Residuales, y = X_5)) +
  geom_point(alpha = 0.7) +
  labs(title = "vs. sample_questions", x = "Residuales", y = "sample_questions") +
  theme_minimal()

# Plot residuales vs X_1 * X_2
plot7 <- ggplot(muestreado, aes(x = Residuales, y = X1_X2)) +
  geom_point(alpha = 0.7) +
  labs(title = "vs. sample_questions / hrs_studied", x = "Residuales", y = "sample_questions / hrs_studied") +
  theme_minimal()

# Grid
grid.arrange(plot1, plot2, plot3, plot4, plot5, plot6, plot7, ncol = 3)
```

Observaciones:

1. Residuos vs. Valores Ajustados: No hay un patrón claro o forma específica, lo que sugiere que los residuos están distribuidos aleatoriamente y cumplen razonablemente con el supuesto de homocedasticidad.
2. Residuos vs. hrs_studied: Los puntos están dispersos de manera aleatoria, sin un patrón claro, lo que sugiere que no hay una relación no lineal entre hrs_studied y los residuos.
3. Residuos vs. prev_scores: Los puntos se distribuyen de manera aleatoria, pero con una ligera acumulación en ciertos valores altos de prev_scores.
4. Residuos vs. xtr_activities: La dispersión parece equilibrada entre ambas categorías, sin un sesgo claro en los residuos.
5. Residuos vs. sleep_hrs: No se observa un patrón sistemático en los puntos, lo que sugiere que la relación entre sleep_hrs y la variable dependiente está bien modelada.
6. Residuos vs. sample_questions: Los residuos están distribuidos aleatoriamente, lo que indica que no hay problemas aparentes con esta variable en el modelo.
7. Residuos vs. sample_questions / hrs_studied: No se observa un patrón claro, lo que sugiere que esta interacción no presenta problemas significativos en el modelo.

Dicho lo anterior, podemos decir que los residuos parecen distribuidos aleatoriamente en todos los gráficos, lo que respalda los supuestos de homocedasticidad e independencia. Además, no se observan patrones sistemáticos claros que sugieran problemas importantes de linealidad o heterocedasticidad.

\newpage

### 3.  Varianzas no constantes (Heterocedasticidad)

```{r fig.width=10, fig.height=4.5, echo=FALSE}
# Prueba de Brown-Forsythe usando un $\alpha=0.01$
# Residuales
data$residual <- modelo_m$residuals

# Dividiendo grupo por la mediana
grupo.1 <- data[which(modelo_m$fitted.values <= median(modelo_m$fitted.values)),]
grupo.2 <- data[which(modelo_m$fitted.values > median(modelo_m$fitted.values)),]

# Calculando medianas de cada grupo
mediana.epsilon.gorro.1 <- median(grupo.1$residual)
mediana.epsilon.gorro.2 <- median(grupo.2$residual)

# Calculando los valores absolutos de las desviaciones respecto a la mediana
grupo.1$d <- abs(grupo.1$residual-mediana.epsilon.gorro.1)
grupo.2$d <- abs(grupo.2$residual-mediana.epsilon.gorro.2)

# Calculando las medias de las desviaciones absolutas en cada grupo
d.media.1 <- mean(grupo.1$d)
d.media.2 <- mean(grupo.2$d)

# Suma de cuadrados
SSD <-(sum((grupo.1$d - d.media.1)^2) + sum((grupo.2$d - d.media.2)^2)) / (nrow(data) - 2)

# Calculando el estadisticod de prueba
t.star.bf <- abs(d.media.1 - d.media.2)/sqrt(SSD*(1/nrow(grupo.1) + 1/nrow(grupo.2)))
#t.star.bf

# Calculando el valor p
t.star.bf.p.value <- pt(q = t.star.bf, df = nrow(data)-2, lower.tail = FALSE)
#t.star.bf.p.value
print("Prueba de Brown-Forsythe usando un $\alpha=0.01$")
```

Dado que, bajo la hipótesis de varianzas constantes, la estadística de prueba sigue una distribución t, y considerando que el valor calculado de la estadística de prueba es $`r round(t.star.bf, 4)`$ y su correspondiente p-valor es $`r round(t.star.bf.p.value, 5)`$, el cual es no es menor que el nivel de significancia $\alpha = 0.01$. Debido a esto no se rechaza la hipótesis nula ($H_0$). Esto nos permite concluir que no existe evidencia suficiente para afirmar que las varianzas de los grupos no son homogéneas, lo que nos indicaría la presencia de heterocedasticidad en los datos. Por lo tanto, el modelo cumple con el supuesto de homocedasticidad.

```{r fig.width=10, fig.height=4.5, echo=FALSE}
# Prueba de Breusch-Pagan
bp_test <- bptest(modelo_m)
bp_test
```

Como resultado de la prueba Breusch-Pagan implementada, tenemos un $p_{value} = 0.8267$ y un $BP_{statistic} = 2.1594$ a un nivel de significancia igual a $0.05$. Por lo tanto, no se rechaza $H_0$ y nos indica que no hay evidencia de heterocedasticidad en el modelo. Los residuos tienen una varianza aproximadamente constante, lo que cumple con el supuesto de homocedasticidad requerido para un modelo de regresión lineal múltiple. Reafirmando lo que nos decia la prueba Brown-Forsythe.

```{r fig.width=10, fig.height=4.5, echo=FALSE}
# ("hrs_studied", "prev_scores", "xtr_activities", "sleep_hrs", "sample_questions", "performance_idx")
# Residuales 
residuales <- residuals(modelo_m)

# DF auxiliar
df_auxiliar <- data.frame(
  residuales_abs = abs(residuales),
  hrs_studied = data$hrs_studied,
  prev_scores = data$prev_scores,
  xtr_activities = data$xtr_activities,
  sleep_hrs = data$sleep_hrs,
  sample_questions = data$sample_questions
)

# Prueba de Glejser 
glejser_model <- lm(data=df_auxiliar, residuales_abs ~ hrs_studied + prev_scores + xtr_activities + sleep_hrs + sample_questions)

# Resumen del modelo Glejser
summary(glejser_model)
```

Como podemos observar, el resultado del modelo de Glejser respalda los resultados obtenidos previamente con la prueba de Breusch-Pagan y Brown-Forsythe. No se detecta heterocedasticidad en el modelo, lo que confirma que los residuos tienen una varianza constante. Esto  termina por validar este supuesto fundamental de la regresión lineal múltiple y respalda la confiabilidad.

### 4. Normalidad

```{r, fig.align='center', fig.width=3.5, fig.height=2, echo=FALSE}
# QQ Plot
ggplot(residuals_df, aes(sample = Residuales)) +
  stat_qq() +
  stat_qq_line(color = "red") +
  labs(title = "QQ Plot Residuales", x = "Cuantiles Teóricos", y = "Cuantiles Residuales") +
  theme_minimal()
```

* Como podemos observar en el QQ-plot, la mayoría de los puntos están alineados con la línea de referencia, lo que sugiere que los residuos siguen aproximadamente una distribución normal. 
* Por otro lado, en las colas, hay ligeras desviaciones de la línea. Esto indica que podría haber algunos residuos que no siguen perfectamente una distribución normal, lo que podría deberse a valores atípicos.

```{r, fig.align='center', fig.width=8, fig.height=5, echo=FALSE}
# Residuales del modelo
residuales <- residuals(modelo_m)
residuos_submuestra <- sample(residuales, size = 5000, replace = FALSE)

# Prueba de Shapiro-Wilk
prueba_sw <- shapiro.test(residuos_submuestra)
prueba_sw
```

Dado que el $p_{value}$ es mayor a 0.05, en la prueba Shapiro-Wilk, no se rechaza la hipótesis nula. Esto indica que los residuos del modelo pueden considerarse normalmente distribuidos. Por lo tanto, ahora mas formalmente, podemos decri que se cumple este supuesto.

### 5. Multicolinealidad

\vspace{-15mm}

```{r, fig.align='center', fig.width=5, fig.height=4, echo=FALSE}
# Matriz de correlaciones
data_cor <- data[, c("hrs_studied", "prev_scores", "sleep_hrs", "sample_questions", "performance_idx")]
cor_matrix <- round(cor(data_cor), 3)

# Plot
corrplot(cor_matrix, 
         method = "circle", 
         type = "upper", 
         tl.col = "black", 
         tl.srt = 45, 
         addCoef.col = "black")
```

\vspace{-15mm}

El análisis de correlación destaca a prev_scores como el predictor más importante del índice de rendimiento (performance_idx), con una correlación alta de 0.92, indicando una fuerte relación positiva. hrs_studied muestra una correlación moderada (0.37), lo que sugiere que las horas de estudio también influyen, aunque en menor medida. Por el contrario, sleep_hrs (0.05) y sample_questions (0.04) tienen correlaciones muy bajas, lo que implica que su impacto en el rendimiento académico es limitado. Además, las bajas correlaciones entre los predictores reducen el riesgo de multicolinealidad, lo que respalda la estabilidad del modelo ajustado.

```{r fig.align='center', fig.width=5, fig.height=1, echo=FALSE}
# VIF del modelo original
vif_values <- vif(modelo_m)

# Mostrar la tabla en Markdown
kable(vif_values, col.names = c("Variable","VIF"), 
      caption = "Factores de Inflación de Varianzas (VIF)")
```

Confirmando lo mencionado mas arriba, generado por la matriz de correlación, los factores de inflación de varianza (VIF) calculados para las variables predictoras del modelo muestran valores muy bajos, cercanos a 1. Esto nos indica que no existe multicolinealidad significativa entre las variables. Recordemos que un VIF mayor a 10 suele considerarse un indicador de posible multicolinealidad, mientras que valores cercanos a 1 sugieren que las variables son prácticamente independientes. Este resultado, junto con las bajas correlaciones entre los predictores observadas previamente, respalda la estabilidad del modelo de regresión lineal múltiple planteado para este proyecto.

### Conclusiones finales